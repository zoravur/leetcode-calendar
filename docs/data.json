{
  "problems": [
    {
      "slug": "merge-two-sorted-linked-lists",
      "date": "2026-01-07",
      "problem": "merge-two-sorted-linked-lists",
      "source": "neetcode",
      "difficulty": "easy",
      "time_minutes": 0,
      "topics": [
        "linked-list",
        "sorting"
      ],
      "language": "python",
      "markdown": "## Approach\n\nClassic merge algorithm, all you need to know is pointer manipulation. The dummy list head reduces edge cases.\nGot this one on the first try.\n\n## Solution\n\n```python\n# Definition for singly-linked list.\n# class ListNode:\n#     def __init__(self, val=0, next=None):\n#         self.val = val\n#         self.next = next\n\nclass Solution:\n    def mergeTwoLists(self, list1: Optional[ListNode], list2: Optional[ListNode]) -> Optional[ListNode]:\n        head = ListNode('dummy')\n\n        cur = head\n\n        while list1 is not None and list2 is not None:\n            if list1.val < list2.val:\n                cur.next = list1\n                list1 = list1.next\n                cur = cur.next\n            else:\n                cur.next = list2\n                list2 = list2.next\n                cur = cur.next\n        \n        while list1 is not None:\n            cur.next = list1\n            list1 = list1.next\n            cur = cur.next\n\n        while list2 is not None:\n            cur.next = list2\n            list2 = list2.next\n            cur = cur.next\n\n        return head.next\n\n```\n\n## Complexity\n\n* Time: O(n)\n* Space: O(n) (O(1) additional)\n\n## Results\n\nN/A\n\n## Next Steps\n\nShouldn't've iterated through the linked list after the main merge, because appending the head automatically appends\nthe rest of the list. Meaning:\n\n```python\nwhile list1 is not None:\n    cur.next = list1\n    list1 = list1.next\n    cur = cur.next\n\nwhile list2 is not None:\n    cur.next = list2\n    list2 = list2.next\n    cur = cur.next\n```\n\nshould have been:\n\n```python\nif list1:\n    cur.next = list1\nelse:\n    cur.next = list2\n```\n\n## Notes\n\nNone.\n"
    },
    {
      "slug": "first-missing-positive",
      "date": "2026-01-06",
      "problem": "first-missing-positive",
      "source": "neetcode",
      "difficulty": "hard",
      "time_minutes": 30,
      "topics": [
        "array"
      ],
      "language": "python",
      "markdown": "## Approach\n\nThis'll be a terser explanation, due to time constraints.\n\nI started by doing the algorithm where you move each element to its corresponding sorted index,\nexcept that we would shift the range 1..n to 0..n-1. Then, since the first missing positive integer\nwould be the first mismatch, we'd immediately find the solution upon iterating through the array.\n\nI started by moving each positive integer I encountered in the range 1..n to its corresponding index.\nIn order to preserve the set, I would move the integer in target index to the current position.\nI spent 2 incorrect answers debugging, before I realized that I wasn't replacing the new integer\nat the current position in case it was also in the range. This resulted in me missing certain\nswaps that needed to happen.\n\nBut this was sufficient to get the correct answer.\n\n## Solution\n\n```python\nclass Solution:\n    def firstMissingPositive(self, nums: List[int]) -> int:\n        for i in range(len(nums)):\n            num = nums[i]\n            j = num-1\n\n            while num >= 1 and num <= len(nums) and nums[j] != num:\n                nums[i] = nums[j]\n                nums[j] = num\n                num = nums[i]\n                j = num-1\n\n        for i in range(len(nums)):\n            if nums[i] != i+1:\n                return i+1\n        return len(nums)+1\n\n```\n\n## Complexity\n\n* Time: O(n)\n  * justification: we rotate each subsequence at most once, which means that each element is\n    compared at most twice, which means a constant number of operations per element, or O(n)\n* Space: O(1) (auxiliary)\n  * justification: we never create an array, or create new elements in a loop. All modifications\n    happen in place, meaning that we use no extra space.\n\n## Results\n\nN/A (neetcode)\n\n## Next Steps\n\nFlesh out this explanation in more detail.\nSwitch to using binary search for the final step.\n\n## Notes\n\n\\[Any additional notes]\n"
    },
    {
      "slug": "string-encode-and-decode",
      "date": "2026-01-04",
      "problem": "string-encode-and-decode",
      "source": "neetcode",
      "difficulty": "medium",
      "time_minutes": 10,
      "topics": [
        "string",
        "design"
      ],
      "language": "python",
      "markdown": "## Problem\n\nDesign an algorithm to encode a list of strings to a string. The encoded string is then sent over the network and is decoded back to the original list of strings.\n\n## Approach\n\nFirst approach was to cheat a bit, just to see if it would work. `repr()` converts a python value to a\nstring that evaluates to the original value. Then, ast.literal\\_eval on the other side is the\n\"inverse\" of repr that definitely works for relatively simple things like lists of strings.\n\nHow does repr and ast.literal\\_eval encode values as python objects? Fundamentally, the core problem with\nany parsing task such as this is separating the data from the metadata. How do you know if something is\na value or not? That's done through program state. Roughly, here's the matrix:\n\n+---------------------+----------------------------------------------------------------------+------------------------------------------------------------+\n| Expecting \\ Actual  | Data                                                                 |  Metadata                                                  |\n+---------------------+----------------------------------------------------------------------+------------------------------------------------------------+\n| Data                | Normal parse                                                         |  dropped headers / fields; bad state, security risk likely |\n| Metadata            | Direct injection risk, very bad. User controls program control flow  |  Normal parse                                              |\n+---------------------+----------------------------------------------------------------------+------------------------------------------------------------+\n\nBecause we control both the encoder and the decoder, we can easily sync the initial state. We can either start with data/data,\nor metadata/metadata. How do we pick which is better?\n\nSuppose we chose our algorithm to start on data/data. Great. We start transmitting the string, one\ncharacter at a time. How do we know when the next string begins? We could emit a special character\nsequence, called a delimiter. but the problem is that the string itself could contain any possible\nascii sequence! That makes it impsosible to tell whether the delimiter represents the end of the\nstring, or is part of the string itself.\n\nHere, one possible approach is try to make this work by mapping some characters onto two character\nsequences -- we call this \"escaping\". For instance, we could say that strings are null terminated,\nalways ending in `chr(0)`, or `'\\0'`. But then, what happens if `chr(0)` is in the string itself? Then,\nwe would escape, letting `\"\\\\0\"` represent the null terminator if it's in a string. But then what\nabout `'\\'` itself? Well, we would map that one to `'\\\\'`. Now, `'\\'` is a special character that determines\nhow the next character is processed, and `chr(0)` actually never appears directly in the strings\nthemselves.\n\nThis is complicated! Luckily, there is a simpler approach, which is what I used. If we switch to\nmetadata/metadata to start, we can include everything needed to process the first string right at\nthe beginning. If we prefix each string with its length, we can process the following data\nup to that length, before switching back to processing metadata. here's what I mean:\n\n```\n[\"Hello\", \"world\"] -> [5Hello5world]\n```\n\nDecoding, we read off the number at the start, process that many characters and append it to our list,\nwhich reverses the above.\n\nThere's some problems with this approach. How do we know when the number ends? What if\nthe string starts with a number, For instance, take the following cases:\n\n```\n[\"verylongstring\", \"wow\"] -> 14verylongstring3wow\n[\"1337\", \"speak\"] -> 413375speak\n```\n\nIn the first example, we read off multiple digits to handle a string over 9 characters. All's well and good,\nwe can just stop parsing after the first non-digit. But as soon as we try to implement that, the second\ncase bites us: we try to read a string of length 413375, not knowing that the first string actually\nconsists of the numbers \"1337\".\n\nHere, we need only introduce a separator between the number and the string it represents. ',' works fine\n\\-- it unambiguously signals the end of the number.\n\nThis works and is the most flexible approach, but it's a bit annoying that the number spans multiple characters.\nSo, I noticed that the max string length was 200 <= 255 = 2^8-1, the max size of a char, meaning we could use a\nsingle character to store the length.\n\nSo that's how my solution deviates. I use a single char/byte anyway, relying on the fact that strings are at most\n200 characters long. But even if we allowed infinite length strings, the previous approach still works.\n\nI also add a 255 as a control character to determine the end of the sequence. This is not required for the\nproblem, as we have the full string and can check if the string is empty. But in real network scenarios,\nwe might run into a situation where we are streaming data and it's not obvious that the data is finished.\nWhich is why I included that.\n\n## Solution\n\n```python\nclass Solution:\n\n    def encode(self, strs: List[str]) -> str:\n        return ''.join(s for t in zip((chr(len(s)) for s in strs), strs) for s in t) + chr(255)\n\n    def decode(self, s: str) -> List[str]:\n        res = []\n        while ord(s[0]) != 255:\n            l = ord(s[0])\n            res.append(s[1:l+1])\n            s = s[l+1:]\n        return res\n\n\n```\n\n## Complexity\n\n* Time: O(n)\n* Space: O(n)\n\n## Results\n\nN/A (neetcode)\n\n## Next Steps\n\nNeed to improve explanation. Should get better at talking and start recording self.\n\n## Notes\n\nNo notes this time. Straight to implementation.\n"
    },
    {
      "slug": "top-k-frequent-elements",
      "date": "2026-01-03",
      "problem": "top-k-frequent-elements",
      "source": "neetcode",
      "difficulty": "medium",
      "time_minutes": 15,
      "topics": [
        "array",
        "hash-map"
      ],
      "language": "python",
      "markdown": "This problem was harder than I expected, and it didn't occur to me immediately how to solve it,\nso I started checking hints (bad, I know). The key insight is that frequencies form a partition.\n\nOnce that was clear, it was easy to organize the collection by frequency, and then select off\nthe top k most frequent elements.\n\n## Problem\n\n> Given an integer array nums and an integer k, return the k most frequent elements within the array.\n> The test cases are generated so that the solution is unique.\n\n## Approach\n\nThe simplest solution would be to generate counts (with a dict), then convert to an array, and sort and\nextract the top k elements.\n\nThis solution works, but has a step that is O(nlogn) -- sorting the array.\n\nHow can we reduce this O(nlogn) step to O(n)? The key (no pun intended) is realizing that\nthe range of frequency values are bounded -- the highest possible frequency is n itself,\nbecause there are at most n elements in the array. It forms a partition.\n\nThat means that if we can somehow look up elements based on their frequency, we can\njust iterate from n down to 0, printing the first k elements we encounter.\n\nTherefore, we need only to maintain a grouping of elements by their frequency (which we can hold\nin an array because the key values are 0..n), which we can during the count, or after, all in\none shot. Here, I opted to construct it incrementally, but 3 passes might have been faster.\n\nAs promised, we select the top k elements, which is what the last statement does in a more\nfunctional style.\n\n## Solution\n\n```python\nclass Solution:\n    def topKFrequent(self, nums: List[int], k: int) -> List[int]:\n        d = collections.defaultdict(int)\n        groups = [set(nums)] + [set() for _ in range(len(nums))]\n        for num in nums:\n            i = d[num]\n            d[num] += 1\n            groups[i].remove(num)\n            groups[i+1].add(num)\n        return [num for s in groups for num in s][-k:]\n\n```\n\n## Complexity\n\nTODO\n\n* Time: O(n)\n* Space: O(n)\n\n## Notes\n\nIt's not immediately obvious to me how to solve this one.\nAfter looking at hint 1 and 2, it says I'm supposed to\ngroup numbers based on their frequency.\nit's also obvious that my solution should be O(n) time.\nIf we had a dictionary from frequency -> set of values,\nThen I could start from the highest frequency and move down\nIterating through the range of frequency values could be expensive.\nActually, since the frequencies form a partition of n, the\nlength of the list, I have to through n -> 0 to hit every\npossible frequency.\nAnd we could further optimize by using a list of sets\ninstead of a dictionary of sets. That would improve performance.\n"
    },
    {
      "slug": "anagram-groups",
      "date": "2026-01-02",
      "problem": "anagram-groups",
      "source": "neetcode",
      "difficulty": "medium",
      "time_minutes": 10,
      "topics": [
        "hash-map",
        "string"
      ],
      "language": "python",
      "markdown": "## Approach\n\nThis problem is mostly about clean implementation once you know that the best way to determine\nanagrams is by counting characters. There's the added wrinkle that your counts object is not\nhashable, which means it's hard to group strings based on them having the same counts. But\nthat's easy if you either use a frozenset, which allows you to hash non hashable types, or you\ndo what I did, and convert the unhashable type to a canonical string directly.\n\nI could have also used python Counters, to make it even easier, but I haven't fully memorized\nthe API so I thought it'd be better if I stuck to less powerful approaches.\n\ncollections.defaultdict is very powerful though, and worth learning.\n\n## Solution\n\n```python\nclass Solution:\n    def countsToKey(self, d: dict) -> str:\n        return ','.join(str(d[chr(ord('a')+i)]) for i in range(26))\n\n    def strToCounts(self, s: str) -> dict:\n        d = collections.defaultdict(int)\n        for c in s:\n            d[c] += 1\n        return d\n\n    def groupAnagrams(self, strs: List[str]) -> List[List[str]]:\n        d = {}\n        for s in strs:\n            k = self.countsToKey(self.strToCounts(s))\n            if k not in d:\n                d[k] = []\n            d[k].append(s)\n        return list(d.values())\n\n```\n\n## Complexity\n\n* Time: O(n)\n* Space: O(n)\n\n## Results\n\nN/A (NeetCode)\n\n## Next Steps\n\nThere's a little bit of inconsistency with the APIs used, as I threw in\ncollections.defaultdict to fix a bug with key generation. Sticking to something simpler\ndespite the annoyance, or going all out with all the upgraded APIs, would probably be better.\n\nClaude suggested I used tuple() instead of string generation, for a few reasons:\n\n* Hashing — Tuples of ints hash directly. Strings require hashing each character, and your string is longer (commas, multi-digit numbers) than a 26-int tuple's logical content.\n* String building — ','.join(...) creates intermediate strings and a generator. tuple(counts) on a list is a single C-level copy.\n* Memory — \"0,0,0,3,0,...\" takes more bytes than (0,0,0,3,0,...) since each digit is a character.\n\nWill try to remember tuples for future problems.\n\n## Notes\n\nN/A\n"
    },
    {
      "slug": "n-queens",
      "date": "2026-01-01",
      "problem": "n-queens",
      "source": "leetcode",
      "difficulty": "hard",
      "time_minutes": 90,
      "topics": [
        "backtracking"
      ],
      "language": "python",
      "markdown": "## Approach\n\nThis is a pretty standard backtracking problem. You generate all the possible boards, but save only the ones\nthat are valid. Halfway through, I generated some binary strings as practice:\n\n```python\ndef binaryStringsRec(l: int):\n    result = []\n    if l == 0:\n        result.append([])\n        return result\n    for c in ['0', '1']:\n        for s in binaryStringsRec(l-1):\n            result.append([c]+s)\n    return result\n\ndef binaryStrings(l=8):\n    return [''.join(s) for s in binaryStringsRec(l)];\n```\n\nIn all backtracking problems, we need a way to generate correct partial results (that are correct),\nand progressively build them into full solutions. A binary string consists of 0 or 1 prepended to\na binary string. If length is a parameter, it determines our base case. In the n-queens problem,\na valid solutions is a board where no queens are attacking each other, and our base case is when\nthe number of queens is equal to the number of rows and columns on the board (because we can't\nplace more).\n\nIf we can swap out the logic in the recursive helper, by enumerating and combining board positions\ninstead of 0s or 1s, we'd be well on our way to generating a correct solution.\n\nI started by thinking about my board representation. I decided to go with an unrolled list of length n\\*n,\nas in a matrix in row major order. The two primary advantages of this approach (as opposed to a list\nof lists) is that I need only one integer as my index, and that it makes cloning easier (via slicing).\nThen I started thinking of a way to generate queen moves from a queen position. It was easiest to\nthink of this in 2d, so I just created two small helpers to convert to and from a 2d index. And those\nhelpers gave me a nice opportunity to detect moves off the board as well, so I added that.\n\nThen, in an effort to simplify things further, I wrote markQueenMoves, and made it modify an existing\nboard instead of returning a new board. This allowed me to not worry about combining moves from two\nboards, as I might do if I were writing in a more functional style. This was a choice out of convenience.\n\nsolveNQueensRec is the meat of the logic. But that too isn't terribly complicated. You can't place a\nqueen on a covered square, and once you've placed a queen, if it's your last queen, you're done, and\nif it's not, you place the current queen, and then call the function again to place the remaining\nqueens. We return an list because we're accumulating results, not just determining if a solution\nexists. naturally, an empty list corresponds to no solutions, which means we can combine lists using\nthe + operator, or via append / extend.\n\nsolveNQueens is just a wrapper for the recursive helper, and the signature required by the question.\n\nAfter testing on a 9x9 board, there was just one small wrinkle -- TLE. Turns out you can't enumerate\nEVERY possible queen position as it's too inefficient. There are three levels to the inefficiency:\n\n1. True (n^2)!/(n^2-n)! -- least efficient, but every possible enumeration counting duplicates\n2. (n^2)Cn -- easy if you constrain each queen to start after the one placed before it. Cuts down by a n! factor.\n3. Row-wise enumeration (just snuck me into passing). Force each queen to start on a new row, but\n   that's all. This leverages the fact that new queens should be on new rows, but there's probably\n   more optimizations you could make.\n\n## Complexity\n\n* Time: O(n^n)\n  Reason: We try every row and every column at most once\n* Space: O(?)\n  Not sure on this one. My initial thought was the number of active boards is proportional to the depth of\n  recursion, so O(n^3) because each board is O(n^2) and recursion depth is O(n). But if we count the solution\n  size, it gets more complicated and turns into a counting problem. An upper bound for it is O(n!n!)\n  (permutations of rows and columns) but that's also wildly overestimating the set of solutions that are\n  valid.\n\n## Results\n\n119ms (5.58th percentile)\n18.29MB (42.66%)\n\nNot good, but not bad for a first hard problem after being rusty.\n\n## Next Steps\n\nI intend to revisit this problem. I think an approach where you slot each queen into a row, column, and\ndiagonals, might lead to a faster solution.\n\n## Notes\n\n* pretty standard backtracking.\n* i'm sure we could do some invariant stuff with eightfold symmetry, but let's keep it\n* simple to start.\n* brute force with backtracking.\n* We'll need a way to mark off squares that are covered.\n* We'll also need a way to mark off covered squares every time we place a queen.\n* We could use a boolean array from 1..n^2 for this.\n* but first we need a way to generate queen moves.\n"
    }
  ],
  "heatmapData": [
    {
      "date": "2025-12-31",
      "count": 0,
      "level": 0
    },
    {
      "date": "2026-01-01",
      "count": 1,
      "level": 4
    },
    {
      "date": "2026-01-02",
      "count": 1,
      "level": 4
    },
    {
      "date": "2026-01-03",
      "count": 1,
      "level": 4
    },
    {
      "date": "2026-01-04",
      "count": 1,
      "level": 4
    },
    {
      "date": "2026-01-05",
      "count": 0,
      "level": 0
    },
    {
      "date": "2026-01-06",
      "count": 1,
      "level": 4
    },
    {
      "date": "2026-01-07",
      "count": 1,
      "level": 4
    }
  ],
  "cumulativeData": {
    "dates": [
      "2026-01-01",
      "2026-01-02",
      "2026-01-03",
      "2026-01-04",
      "2026-01-05",
      "2026-01-06",
      "2026-01-07"
    ],
    "actual": [
      1,
      2,
      3,
      4,
      4,
      5,
      6
    ],
    "trend": [
      1,
      2,
      3,
      4,
      5,
      6,
      7
    ]
  }
}